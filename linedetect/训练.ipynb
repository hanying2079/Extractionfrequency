{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5fc7a5",
   "metadata": {},
   "source": [
    "# 将打标签的json转化为数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0e5d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1.jpg and 1.png\n",
      "Saved 10.jpg and 10.png\n",
      "Saved 100.jpg and 100.png\n",
      "Saved 101.jpg and 101.png\n",
      "Saved 102.jpg and 102.png\n",
      "Saved 103.jpg and 103.png\n",
      "Saved 104.jpg and 104.png\n",
      "Saved 105.jpg and 105.png\n",
      "Saved 106.jpg and 106.png\n",
      "Saved 107.jpg and 107.png\n",
      "Saved 108.jpg and 108.png\n",
      "Saved 109.jpg and 109.png\n",
      "Saved 11.jpg and 11.png\n",
      "Saved 110.jpg and 110.png\n",
      "Saved 111.jpg and 111.png\n",
      "Saved 112.jpg and 112.png\n",
      "Saved 113.jpg and 113.png\n",
      "Saved 114.jpg and 114.png\n",
      "Saved 115.jpg and 115.png\n",
      "Saved 116.jpg and 116.png\n",
      "Saved 117.jpg and 117.png\n",
      "Saved 118.jpg and 118.png\n",
      "Saved 119.jpg and 119.png\n",
      "Saved 12.jpg and 12.png\n",
      "Saved 120.jpg and 120.png\n",
      "Saved 121.jpg and 121.png\n",
      "Saved 122.jpg and 122.png\n",
      "Saved 123.jpg and 123.png\n",
      "Saved 124.jpg and 124.png\n",
      "Saved 125.jpg and 125.png\n",
      "Saved 126.jpg and 126.png\n",
      "Saved 127.jpg and 127.png\n",
      "Saved 128.jpg and 128.png\n",
      "Saved 129.jpg and 129.png\n",
      "Saved 13.jpg and 13.png\n",
      "Saved 130.jpg and 130.png\n",
      "Saved 131.jpg and 131.png\n",
      "Saved 132.jpg and 132.png\n",
      "Saved 133.jpg and 133.png\n",
      "Saved 134.jpg and 134.png\n",
      "Saved 135.jpg and 135.png\n",
      "Saved 136.jpg and 136.png\n",
      "Saved 137.jpg and 137.png\n",
      "Saved 138.jpg and 138.png\n",
      "Saved 139.jpg and 139.png\n",
      "Saved 14.jpg and 14.png\n",
      "Saved 140.jpg and 140.png\n",
      "Saved 141.jpg and 141.png\n",
      "Saved 142.jpg and 142.png\n",
      "Saved 143.jpg and 143.png\n",
      "Saved 144.jpg and 144.png\n",
      "Saved 145.jpg and 145.png\n",
      "Saved 146.jpg and 146.png\n",
      "Saved 147.jpg and 147.png\n",
      "Saved 148.jpg and 148.png\n",
      "Saved 149.jpg and 149.png\n",
      "Saved 15.jpg and 15.png\n",
      "Saved 150.jpg and 150.png\n",
      "Saved 151.jpg and 151.png\n",
      "Saved 152.jpg and 152.png\n",
      "Saved 153.jpg and 153.png\n",
      "Saved 154.jpg and 154.png\n",
      "Saved 155.jpg and 155.png\n",
      "Saved 156.jpg and 156.png\n",
      "Saved 157.jpg and 157.png\n",
      "Saved 158.jpg and 158.png\n",
      "Saved 159.jpg and 159.png\n",
      "Saved 16.jpg and 16.png\n",
      "Saved 160.jpg and 160.png\n",
      "Saved 161.jpg and 161.png\n",
      "Saved 162.jpg and 162.png\n",
      "Saved 163.jpg and 163.png\n",
      "Saved 164.jpg and 164.png\n",
      "Saved 165.jpg and 165.png\n",
      "Saved 166.jpg and 166.png\n",
      "Saved 167.jpg and 167.png\n",
      "Saved 168.jpg and 168.png\n",
      "Saved 169.jpg and 169.png\n",
      "Saved 17.jpg and 17.png\n",
      "Saved 170.jpg and 170.png\n",
      "Saved 171.jpg and 171.png\n",
      "Saved 172.jpg and 172.png\n",
      "Saved 173.jpg and 173.png\n",
      "Saved 174.jpg and 174.png\n",
      "Saved 175.jpg and 175.png\n",
      "Saved 176.jpg and 176.png\n",
      "Saved 177.jpg and 177.png\n",
      "Saved 178.jpg and 178.png\n",
      "Saved 179.jpg and 179.png\n",
      "Saved 18.jpg and 18.png\n",
      "Saved 180.jpg and 180.png\n",
      "Saved 181.jpg and 181.png\n",
      "Saved 182.jpg and 182.png\n",
      "Saved 183.jpg and 183.png\n",
      "Saved 184.jpg and 184.png\n",
      "Saved 185.jpg and 185.png\n",
      "Saved 186.jpg and 186.png\n",
      "Saved 187.jpg and 187.png\n",
      "Saved 188.jpg and 188.png\n",
      "Saved 189.jpg and 189.png\n",
      "Saved 19.jpg and 19.png\n",
      "Saved 190.jpg and 190.png\n",
      "Saved 191.jpg and 191.png\n",
      "Saved 192.jpg and 192.png\n",
      "Saved 193.jpg and 193.png\n",
      "Saved 194.jpg and 194.png\n",
      "Saved 195.jpg and 195.png\n",
      "Saved 196.jpg and 196.png\n",
      "Saved 197.jpg and 197.png\n",
      "Saved 198.jpg and 198.png\n",
      "Saved 199.jpg and 199.png\n",
      "Saved 2.jpg and 2.png\n",
      "Saved 20.jpg and 20.png\n",
      "Saved 200.jpg and 200.png\n",
      "Saved 201.jpg and 201.png\n",
      "Saved 202.jpg and 202.png\n",
      "Saved 203.jpg and 203.png\n",
      "Saved 204.jpg and 204.png\n",
      "Saved 205.jpg and 205.png\n",
      "Saved 206.jpg and 206.png\n",
      "Saved 207.jpg and 207.png\n",
      "Saved 21.jpg and 21.png\n",
      "Saved 22.jpg and 22.png\n",
      "Saved 23.jpg and 23.png\n",
      "Saved 24.jpg and 24.png\n",
      "Saved 25.jpg and 25.png\n",
      "Saved 26.jpg and 26.png\n",
      "Saved 27.jpg and 27.png\n",
      "Saved 28.jpg and 28.png\n",
      "Saved 29.jpg and 29.png\n",
      "Saved 3.jpg and 3.png\n",
      "Saved 30.jpg and 30.png\n",
      "Saved 31.jpg and 31.png\n",
      "Saved 32.jpg and 32.png\n",
      "Saved 33.jpg and 33.png\n",
      "Saved 34.jpg and 34.png\n",
      "Saved 35.jpg and 35.png\n",
      "Saved 36.jpg and 36.png\n",
      "Saved 37.jpg and 37.png\n",
      "Saved 38.jpg and 38.png\n",
      "Saved 39.jpg and 39.png\n",
      "Saved 4.jpg and 4.png\n",
      "Saved 40.jpg and 40.png\n",
      "Saved 41.jpg and 41.png\n",
      "Saved 42.jpg and 42.png\n",
      "Saved 43.jpg and 43.png\n",
      "Saved 44.jpg and 44.png\n",
      "Saved 45.jpg and 45.png\n",
      "Saved 46.jpg and 46.png\n",
      "Saved 47.jpg and 47.png\n",
      "Saved 48.jpg and 48.png\n",
      "Saved 49.jpg and 49.png\n",
      "Saved 5.jpg and 5.png\n",
      "Saved 50.jpg and 50.png\n",
      "Saved 51.jpg and 51.png\n",
      "Saved 52.jpg and 52.png\n",
      "Saved 53.jpg and 53.png\n",
      "Saved 54.jpg and 54.png\n",
      "Saved 55.jpg and 55.png\n",
      "Saved 56.jpg and 56.png\n",
      "Saved 57.jpg and 57.png\n",
      "Saved 58.jpg and 58.png\n",
      "Saved 59.jpg and 59.png\n",
      "Saved 6.jpg and 6.png\n",
      "Saved 60.jpg and 60.png\n",
      "Saved 61.jpg and 61.png\n",
      "Saved 62.jpg and 62.png\n",
      "Saved 63.jpg and 63.png\n",
      "Saved 64.jpg and 64.png\n",
      "Saved 65.jpg and 65.png\n",
      "Saved 66.jpg and 66.png\n",
      "Saved 67.jpg and 67.png\n",
      "Saved 68.jpg and 68.png\n",
      "Saved 69.jpg and 69.png\n",
      "Saved 7.jpg and 7.png\n",
      "Saved 70.jpg and 70.png\n",
      "Saved 71.jpg and 71.png\n",
      "Saved 72.jpg and 72.png\n",
      "Saved 73.jpg and 73.png\n",
      "Saved 74.jpg and 74.png\n",
      "Saved 75.jpg and 75.png\n",
      "Saved 76.jpg and 76.png\n",
      "Saved 77.jpg and 77.png\n",
      "Saved 78.jpg and 78.png\n",
      "Saved 79.jpg and 79.png\n",
      "Saved 8.jpg and 8.png\n",
      "Saved 80.jpg and 80.png\n",
      "Saved 81.jpg and 81.png\n",
      "Saved 82.jpg and 82.png\n",
      "Saved 83.jpg and 83.png\n",
      "Saved 84.jpg and 84.png\n",
      "Saved 85.jpg and 85.png\n",
      "Saved 86.jpg and 86.png\n",
      "Saved 87.jpg and 87.png\n",
      "Saved 88.jpg and 88.png\n",
      "Saved 89.jpg and 89.png\n",
      "Saved 9.jpg and 9.png\n",
      "Saved 90.jpg and 90.png\n",
      "Saved 91.jpg and 91.png\n",
      "Saved 92.jpg and 92.png\n",
      "Saved 93.jpg and 93.png\n",
      "Saved 94.jpg and 94.png\n",
      "Saved 95.jpg and 95.png\n",
      "Saved 96.jpg and 96.png\n",
      "Saved 97.jpg and 97.png\n",
      "Saved 98.jpg and 98.png\n",
      "Saved 99.jpg and 99.png\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from labelme import utils\n",
    "import cv2\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #存放原图片的路径\n",
    "    jpgs_path   = \"datasets/JPEGImages\"\n",
    "    #存放对应的标签图片路径\n",
    "    pngs_path   = \"datasets/SegmentationClass\"\n",
    "    #标签类别\n",
    "    classes     = [\"_background_\",\"line\"]\n",
    "    #水平特征卷积核\n",
    "    kernel = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    "    \n",
    "    # 如果输出的路径不存在，则自动创建这个路径\n",
    "    if not osp.exists(jpgs_path):\n",
    "        os.mkdir(jpgs_path)\n",
    "    if not osp.exists(pngs_path):\n",
    "        os.mkdir(pngs_path)\n",
    "    \n",
    "    #os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。\n",
    "    count = os.listdir(\"./datasets/before/\") \n",
    "    for i in range(0, len(count)):\n",
    "        #路径拼接文件路径\n",
    "        path = os.path.join(\"./datasets/before\", count[i])\n",
    "        \n",
    "        #os.path.isfile()：判断某一对象(需提供绝对路径)是否为文件\n",
    "        #endswith()：判断字符串是否以指定字符或子字符串结尾。\n",
    "        if os.path.isfile(path) and path.endswith('json'):\n",
    "            #加载json数据\n",
    "            data = json.load(open(path))\n",
    "            \n",
    "            #获取json里面的图片数据(二进制数据)，如果没有imageData属性，就重新读取数据\n",
    "            if data['imageData']:\n",
    "                imageData = data['imageData']\n",
    "            else:\n",
    "                #os.path.dirname()：去掉文件名，返回目录\n",
    "                imagePath = os.path.join(os.path.dirname(path), data['imagePath'])\n",
    "                #rb: 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。\n",
    "                with open(imagePath, 'rb') as f:\n",
    "                    imageData = f.read()\n",
    "                    #对图像的编码与解码\n",
    "                    imageData = base64.b64encode(imageData).decode('utf-8')\n",
    "            # 将二进制数据转变为numpy格式的数据        \n",
    "            img = utils.img_b64_to_arr(imageData)\n",
    "            \n",
    "            #将类别名称转换成数值，以便于计算\n",
    "            label_name_to_value = {'_background_': 0}\n",
    "            for shape in data['shapes']:\n",
    "                label_name = shape['label']\n",
    "                if label_name in label_name_to_value:\n",
    "                    label_value = label_name_to_value[label_name]\n",
    "                else:\n",
    "                    label_value = len(label_name_to_value)\n",
    "                    label_name_to_value[label_name] = label_value\n",
    "            \n",
    "            # label_values必须是密集的\n",
    "            label_values, label_names = [], []\n",
    "            for ln, lv in sorted(label_name_to_value.items(), key=lambda x: x[1]):\n",
    "                label_values.append(lv)\n",
    "                label_names.append(ln)\n",
    "            #确保label_values必须是密集的，连续的(例如：0,1,2,3,...)\n",
    "            assert label_values == list(range(len(label_values)))\n",
    "            \n",
    "            #解析'shapes'中的字段信息，解析出每个对象的mask与对应的label\n",
    "            #lbl存储 mask，lbl_names 存储对应的label\n",
    "            #lbl 像素取值 0、1、2、3、4 其中0对应背景，1对应第一个对象，2对应第二个对象……以此类推\n",
    "            lbl = utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)\n",
    "            \n",
    "            #将原图进行水平过滤实现线性增强,将数组转换为图片，并保存到指定的路径下 \n",
    "            new_img = cv2.filter2D(img,-1,kernel)\n",
    "            PIL.Image.fromarray(new_img).save(osp.join(jpgs_path, count[i].split(\".\")[0]+'.jpg'))\n",
    "\n",
    "            new = np.zeros([np.shape(img)[0],np.shape(img)[1]])\n",
    "            for name in label_names:\n",
    "                index_json = label_names.index(name)\n",
    "                index_all = classes.index(name)\n",
    "                new = new + index_all*(np.array(lbl) == index_json)\n",
    "\n",
    "            utils.lblsave(osp.join(pngs_path, count[i].split(\".\")[0]+'.png'), new)\n",
    "            print('Saved ' + count[i].split(\".\")[0] + '.jpg and ' + count[i].split(\".\")[0] + '.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e227a",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad2b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\ipykernel_launcher.py:68: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate txt in ImageSets.\n",
      "train and val size 207\n",
      "traub suze 186\n",
      "Generate txt in ImageSets done.\n",
      "Check datasets format, this may take a while.\n",
      "检查数据集格式是否符合要求，这可能需要一段时间。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 207/207 [00:00<00:00, 453.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印像素点的值与数量。\n",
      "-------------------------------------\n",
      "|             Key |           Value |\n",
      "-------------------------------------\n",
      "|               0 |        50579480 |\n",
      "-------------------------------------\n",
      "|               1 |         3684328 |\n",
      "-------------------------------------\n",
      "JPEGImages中的图片应当为.jpg文件、SegmentationClass中的图片应当为.png文件。\n",
      "如果格式有误，参考:\n",
      "https://github.com/bubbliiiing/segmentation-format-fix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %load voc_annotation.py\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "#   想要增加测试集修改trainval_percent \n",
    "#   修改train_percent用于改变验证集的比例 9:1\n",
    "#   \n",
    "#   当前该库将测试集当作验证集使用，不单独划分测试集\n",
    "#-------------------------------------------------------#\n",
    "trainval_percent    = 1\n",
    "train_percent       = 0.9\n",
    "#-------------------------------------------------------#\n",
    "#   指向VOC数据集所在的文件夹\n",
    "#   默认指向根目录下的VOC数据集\n",
    "#-------------------------------------------------------#\n",
    "VOCdevkit_path      = 'VOCdevkit'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(0)\n",
    "    print(\"Generate txt in ImageSets.\")\n",
    "    segfilepath     = os.path.join(VOCdevkit_path, 'VOC2007/SegmentationClass')\n",
    "    saveBasePath    = os.path.join(VOCdevkit_path, 'VOC2007/ImageSets/Segmentation')\n",
    "    \n",
    "    temp_seg = os.listdir(segfilepath)\n",
    "    total_seg = []\n",
    "    for seg in temp_seg:\n",
    "        if seg.endswith(\".png\"):\n",
    "            total_seg.append(seg)\n",
    "\n",
    "    num     = len(total_seg)  \n",
    "    list    = range(num)  \n",
    "    tv      = int(num*trainval_percent)  \n",
    "    tr      = int(tv*train_percent)  \n",
    "    trainval= random.sample(list,tv)  \n",
    "    train   = random.sample(trainval,tr)  \n",
    "    \n",
    "    print(\"train and val size\",tv)\n",
    "    print(\"traub suze\",tr)\n",
    "    ftrainval   = open(os.path.join(saveBasePath,'trainval.txt'), 'w')  \n",
    "    ftest       = open(os.path.join(saveBasePath,'test.txt'), 'w')  \n",
    "    ftrain      = open(os.path.join(saveBasePath,'train.txt'), 'w')  \n",
    "    fval        = open(os.path.join(saveBasePath,'val.txt'), 'w')  \n",
    "    \n",
    "    for i in list:  \n",
    "        name = total_seg[i][:-4]+'\\n'  \n",
    "        if i in trainval:  \n",
    "            ftrainval.write(name)  \n",
    "            if i in train:  \n",
    "                ftrain.write(name)  \n",
    "            else:  \n",
    "                fval.write(name)  \n",
    "        else:  \n",
    "            ftest.write(name)  \n",
    "    \n",
    "    ftrainval.close()  \n",
    "    ftrain.close()  \n",
    "    fval.close()  \n",
    "    ftest.close()\n",
    "    print(\"Generate txt in ImageSets done.\")\n",
    "\n",
    "    print(\"Check datasets format, this may take a while.\")\n",
    "    print(\"检查数据集格式是否符合要求，这可能需要一段时间。\")\n",
    "    classes_nums        = np.zeros([256], np.int)\n",
    "    for i in tqdm(list):\n",
    "        name            = total_seg[i]\n",
    "        png_file_name   = os.path.join(segfilepath, name)\n",
    "        if not os.path.exists(png_file_name):\n",
    "            raise ValueError(\"未检测到标签图片%s，请查看具体路径下文件是否存在以及后缀是否为png。\"%(png_file_name))\n",
    "        \n",
    "        png             = np.array(Image.open(png_file_name), np.uint8)\n",
    "        if len(np.shape(png)) > 2:\n",
    "            print(\"标签图片%s的shape为%s，不属于灰度图或者八位彩图，请仔细检查数据集格式。\"%(name, str(np.shape(png))))\n",
    "            print(\"标签图片需要为灰度图或者八位彩图，标签的每个像素点的值就是这个像素点所属的种类。\"%(name, str(np.shape(png))))\n",
    "\n",
    "        classes_nums += np.bincount(np.reshape(png, [-1]), minlength=256)\n",
    "            \n",
    "    print(\"打印像素点的值与数量。\")\n",
    "    print('-' * 37)\n",
    "    print(\"| %15s | %15s |\"%(\"Key\", \"Value\"))\n",
    "    print('-' * 37)\n",
    "    for i in range(256):\n",
    "        if classes_nums[i] > 0:\n",
    "            print(\"| %15s | %15s |\"%(str(i), str(classes_nums[i])))\n",
    "            print('-' * 37)\n",
    "    \n",
    "    if classes_nums[255] > 0 and classes_nums[0] > 0 and np.sum(classes_nums[1:255]) == 0:\n",
    "        print(\"检测到标签中像素点的值仅包含0与255，数据格式有误。\")\n",
    "        print(\"二分类问题需要将标签修改为背景的像素点值为0，目标的像素点值为1。\")\n",
    "    elif classes_nums[0] > 0 and np.sum(classes_nums[1:]) == 0:\n",
    "        print(\"检测到标签中仅仅包含背景像素点，数据格式有误，请仔细检查数据集格式。\")\n",
    "\n",
    "    print(\"JPEGImages中的图片应当为.jpg文件、SegmentationClass中的图片应当为.png文件。\")\n",
    "    print(\"如果格式有误，参考:\")\n",
    "    print(\"https://github.com/bubbliiiing/segmentation-format-fix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3aa1fc",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6343da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "Configurations:\n",
      "----------------------------------------------------------------------\n",
      "|                     keys |                                   values|\n",
      "----------------------------------------------------------------------\n",
      "|              num_classes |                                        2|\n",
      "|                 backbone |                                      vgg|\n",
      "|               model_path |               model_data/unet_vgg_voc.h5|\n",
      "|              input_shape |                               [512, 512]|\n",
      "|               Init_Epoch |                                        0|\n",
      "|             Freeze_Epoch |                                       50|\n",
      "|           UnFreeze_Epoch |                                      100|\n",
      "|        Freeze_batch_size |                                        1|\n",
      "|      Unfreeze_batch_size |                                        1|\n",
      "|             Freeze_Train |                                     True|\n",
      "|                  Init_lr |                                   0.0001|\n",
      "|                   Min_lr |                   1.0000000000000002e-06|\n",
      "|           optimizer_type |                                     adam|\n",
      "|                 momentum |                                      0.9|\n",
      "|            lr_decay_type |                                      cos|\n",
      "|              save_period |                                        5|\n",
      "|                 save_dir |                                     logs|\n",
      "|              num_workers |                                        1|\n",
      "|                num_train |                                      186|\n",
      "|                  num_val |                                       21|\n",
      "----------------------------------------------------------------------\n",
      "Freeze the first 17 layers of total 35 layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 186 samples, val on 21 samples, with batch size 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\ipykernel_launcher.py:386: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 1/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.5225 - _f_score: 0.6787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 68s 234ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.5225 - _f_score: 0.6787 - val_loss: 0.2959 - val__f_score: 0.8412 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 43s 234ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.2571 - _f_score: 0.8409 - val_loss: 0.2279 - val__f_score: 0.8761 - lr: 2.0000e-05\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 5e-05.\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 44s 236ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.2462 - _f_score: 0.8437 - val_loss: 0.2157 - val__f_score: 0.8825 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 44s 236ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.2372 - _f_score: 0.8528 - val_loss: 0.1853 - val__f_score: 0.9004 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 9.997114260712562e-05.\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.2049 - _f_score: 0.8749Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 84.38; mPA: 91.12; Accuracy: 97.73\n",
      "Get miou done.\n",
      "186/186 [==============================] - 47s 253ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.2049 - _f_score: 0.8749 - val_loss: 0.1782 - val__f_score: 0.9038 - lr: 9.9971e-05\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 9.98846040749317e-05.\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 44s 239ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1820 - _f_score: 0.8785 - val_loss: 0.1871 - val__f_score: 0.9017 - lr: 9.9885e-05\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 9.97404853034757e-05.\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 45s 242ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1774 - _f_score: 0.8912 - val_loss: 0.1762 - val__f_score: 0.9036 - lr: 9.9740e-05\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 9.953895432879837e-05.\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 45s 243ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1837 - _f_score: 0.8783 - val_loss: 0.2174 - val__f_score: 0.8838 - lr: 9.9539e-05\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 9.928024612700124e-05.\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 45s 244ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1681 - _f_score: 0.8912 - val_loss: 0.1647 - val__f_score: 0.9086 - lr: 9.9280e-05\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 9.896466234027499e-05.\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1775 - _f_score: 0.8871Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 84.98; mPA: 92.38; Accuracy: 97.79\n",
      "Get miou done.\n",
      "186/186 [==============================] - 48s 259ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1775 - _f_score: 0.8871 - val_loss: 0.1695 - val__f_score: 0.9062 - lr: 9.8965e-05\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 9.85925709251981e-05.\n",
      "Epoch 11/50\n",
      "186/186 [==============================] - 46s 246ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1562 - _f_score: 0.9035 - val_loss: 0.1634 - val__f_score: 0.9137 - lr: 9.8593e-05\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 9.816440572371608e-05.\n",
      "Epoch 12/50\n",
      "186/186 [==============================] - 46s 247ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1628 - _f_score: 0.8993 - val_loss: 0.1802 - val__f_score: 0.9039 - lr: 9.8164e-05\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 9.768066595730097e-05.\n",
      "Epoch 13/50\n",
      "186/186 [==============================] - 46s 247ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1584 - _f_score: 0.8994 - val_loss: 0.1608 - val__f_score: 0.9111 - lr: 9.7681e-05\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 9.714191564488162e-05.\n",
      "Epoch 14/50\n",
      "186/186 [==============================] - 46s 248ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1682 - _f_score: 0.8908 - val_loss: 0.1615 - val__f_score: 0.9098 - lr: 9.7142e-05\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 9.654878294522275e-05.\n",
      "Epoch 15/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1644 - _f_score: 0.9032Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 85.54; mPA: 91.0; Accuracy: 97.97\n",
      "Get miou done.\n",
      "186/186 [==============================] - 49s 263ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1644 - _f_score: 0.9032 - val_loss: 0.1634 - val__f_score: 0.9097 - lr: 9.6549e-05\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 9.590195942451994e-05.\n",
      "Epoch 16/50\n",
      "186/186 [==============================] - 47s 251ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1568 - _f_score: 0.9031 - val_loss: 0.1888 - val__f_score: 0.8978 - lr: 9.5902e-05\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 9.520219925006438e-05.\n",
      "Epoch 17/50\n",
      "186/186 [==============================] - 47s 253ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1447 - _f_score: 0.9067 - val_loss: 0.1604 - val__f_score: 0.9124 - lr: 9.5202e-05\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 9.445031831091757e-05.\n",
      "Epoch 18/50\n",
      "186/186 [==============================] - 48s 258ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1538 - _f_score: 0.9037 - val_loss: 0.1611 - val__f_score: 0.9103 - lr: 9.4450e-05\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 9.364719326662119e-05.\n",
      "Epoch 19/50\n",
      "186/186 [==============================] - 49s 263ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1637 - _f_score: 0.8926 - val_loss: 0.1544 - val__f_score: 0.9162 - lr: 9.3647e-05\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 9.279376052505118e-05.\n",
      "Epoch 20/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1488 - _f_score: 0.9028Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 85.24; mPA: 91.52; Accuracy: 97.88\n",
      "Get miou done.\n",
      "186/186 [==============================] - 52s 279ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1488 - _f_score: 0.9028 - val_loss: 0.1691 - val__f_score: 0.9071 - lr: 9.2794e-05\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 9.189101515060819e-05.\n",
      "Epoch 21/50\n",
      "186/186 [==============================] - 49s 265ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1491 - _f_score: 0.9067 - val_loss: 0.1717 - val__f_score: 0.9034 - lr: 9.1891e-05\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 9.09400097040169e-05.\n",
      "Epoch 22/50\n",
      "186/186 [==============================] - 49s 265ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1558 - _f_score: 0.9011 - val_loss: 0.1565 - val__f_score: 0.9139 - lr: 9.0940e-05\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 8.994185301508727e-05.\n",
      "Epoch 23/50\n",
      "186/186 [==============================] - 50s 268ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1390 - _f_score: 0.9113 - val_loss: 0.1595 - val__f_score: 0.9124 - lr: 8.9942e-05\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 8.889770888986879e-05.\n",
      "Epoch 24/50\n",
      "186/186 [==============================] - 51s 272ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1481 - _f_score: 0.9031 - val_loss: 0.1648 - val__f_score: 0.9114 - lr: 8.8898e-05\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 8.780879475370437e-05.\n",
      "Epoch 25/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1301 - _f_score: 0.9216Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 85.78; mPA: 94.17; Accuracy: 97.87\n",
      "Get miou done.\n",
      "186/186 [==============================] - 53s 285ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1301 - _f_score: 0.9216 - val_loss: 0.1648 - val__f_score: 0.9127 - lr: 8.7809e-05\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 8.667638023176716e-05.\n",
      "Epoch 26/50\n",
      "186/186 [==============================] - 50s 270ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1365 - _f_score: 0.9120 - val_loss: 0.1610 - val__f_score: 0.9127 - lr: 8.6676e-05\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 8.55017856687341e-05.\n",
      "Epoch 27/50\n",
      "186/186 [==============================] - 50s 271ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1372 - _f_score: 0.9135 - val_loss: 0.1486 - val__f_score: 0.9190 - lr: 8.5502e-05\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 8.428638058932339e-05.\n",
      "Epoch 28/50\n",
      "186/186 [==============================] - 51s 273ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1328 - _f_score: 0.9127 - val_loss: 0.1476 - val__f_score: 0.9183 - lr: 8.4286e-05\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 8.303158210148963e-05.\n",
      "Epoch 29/50\n",
      "186/186 [==============================] - 50s 270ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1315 - _f_score: 0.9143 - val_loss: 0.1459 - val__f_score: 0.9216 - lr: 8.3032e-05\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 8.173885324413962e-05.\n",
      "Epoch 30/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1475 - _f_score: 0.9042Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 86.25; mPA: 92.61; Accuracy: 98.03\n",
      "Get miou done.\n",
      "186/186 [==============================] - 53s 286ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1475 - _f_score: 0.9042 - val_loss: 0.1531 - val__f_score: 0.9146 - lr: 8.1739e-05\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 8.04097012812942e-05.\n",
      "Epoch 31/50\n",
      "186/186 [==============================] - 51s 273ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1287 - _f_score: 0.9148 - val_loss: 0.1514 - val__f_score: 0.9171 - lr: 8.0410e-05\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 7.904567594468593e-05.\n",
      "Epoch 32/50\n",
      "186/186 [==============================] - 51s 273ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1313 - _f_score: 0.9174 - val_loss: 0.1484 - val__f_score: 0.9181 - lr: 7.9046e-05\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 7.764836762684128e-05.\n",
      "Epoch 33/50\n",
      "186/186 [==============================] - 51s 273ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1390 - _f_score: 0.9188 - val_loss: 0.1466 - val__f_score: 0.9210 - lr: 7.7648e-05\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 7.621940552675397e-05.\n",
      "Epoch 34/50\n",
      "186/186 [==============================] - 51s 274ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1332 - _f_score: 0.9197 - val_loss: 0.1589 - val__f_score: 0.9159 - lr: 7.6219e-05\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 7.476045575031186e-05.\n",
      "Epoch 35/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1377 - _f_score: 0.9180Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 86.23; mPA: 95.03; Accuracy: 97.92\n",
      "Get miou done.\n",
      "186/186 [==============================] - 53s 287ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1377 - _f_score: 0.9180 - val_loss: 0.1606 - val__f_score: 0.9161 - lr: 7.4760e-05\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 7.327321936769204e-05.\n",
      "Epoch 36/50\n",
      "186/186 [==============================] - 51s 273ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1296 - _f_score: 0.9154 - val_loss: 0.1656 - val__f_score: 0.9125 - lr: 7.3273e-05\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 7.175943042998906e-05.\n",
      "Epoch 37/50\n",
      "186/186 [==============================] - 51s 275ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1489 - _f_score: 0.9009 - val_loss: 0.1619 - val__f_score: 0.9128 - lr: 7.1759e-05\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 7.022085394738895e-05.\n",
      "Epoch 38/50\n",
      "186/186 [==============================] - 51s 274ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1339 - _f_score: 0.9083 - val_loss: 0.1527 - val__f_score: 0.9179 - lr: 7.0221e-05\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 6.86592838312463e-05.\n",
      "Epoch 39/50\n",
      "186/186 [==============================] - 51s 275ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1371 - _f_score: 0.9072 - val_loss: 0.1708 - val__f_score: 0.9097 - lr: 6.8659e-05\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 6.707654080246383e-05.\n",
      "Epoch 40/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1229 - _f_score: 0.9213Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 86.74; mPA: 92.8; Accuracy: 98.11\n",
      "Get miou done.\n",
      "186/186 [==============================] - 54s 288ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1229 - _f_score: 0.9213 - val_loss: 0.1536 - val__f_score: 0.9182 - lr: 6.7077e-05\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 6.547447026861325e-05.\n",
      "Epoch 41/50\n",
      "186/186 [==============================] - 51s 276ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1405 - _f_score: 0.9075 - val_loss: 0.1421 - val__f_score: 0.9226 - lr: 6.5474e-05\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 6.38549401722727e-05.\n",
      "Epoch 42/50\n",
      "186/186 [==============================] - 51s 273ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1375 - _f_score: 0.9084 - val_loss: 0.1452 - val__f_score: 0.9216 - lr: 6.3855e-05\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 6.221983881308912e-05.\n",
      "Epoch 43/50\n",
      "186/186 [==============================] - 51s 275ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1240 - _f_score: 0.9212 - val_loss: 0.1415 - val__f_score: 0.9219 - lr: 6.2220e-05\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 6.057107264610537e-05.\n",
      "Epoch 44/50\n",
      "186/186 [==============================] - 51s 275ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1373 - _f_score: 0.9206 - val_loss: 0.1396 - val__f_score: 0.9245 - lr: 6.0571e-05\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 5.891056405891901e-05.\n",
      "Epoch 45/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1238 - _f_score: 0.9216Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 87.14; mPA: 92.92; Accuracy: 98.18\n",
      "Get miou done.\n",
      "186/186 [==============================] - 54s 290ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1238 - _f_score: 0.9216 - val_loss: 0.1486 - val__f_score: 0.9201 - lr: 5.8911e-05\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 5.72402491302642e-05.\n",
      "Epoch 46/50\n",
      "186/186 [==============================] - 51s 274ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1225 - _f_score: 0.9214 - val_loss: 0.1699 - val__f_score: 0.9127 - lr: 5.7240e-05\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 5.5562075372630704e-05.\n",
      "Epoch 47/50\n",
      "186/186 [==============================] - 51s 274ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1123 - _f_score: 0.9273 - val_loss: 0.1472 - val__f_score: 0.9206 - lr: 5.5562e-05\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 5.387799946155123e-05.\n",
      "Epoch 48/50\n",
      "186/186 [==============================] - 51s 274ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1222 - _f_score: 0.9171 - val_loss: 0.1421 - val__f_score: 0.9228 - lr: 5.3878e-05\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 5.2189984954205413e-05.\n",
      "Epoch 49/50\n",
      "186/186 [==============================] - 51s 275ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1305 - _f_score: 0.9059 - val_loss: 0.1431 - val__f_score: 0.9237 - lr: 5.2190e-05\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 5.05e-05.\n",
      "Epoch 50/50\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1387 - _f_score: 0.9104Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 87.15; mPA: 91.42; Accuracy: 98.25\n",
      "Get miou done.\n",
      "186/186 [==============================] - 54s 290ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1387 - _f_score: 0.9104 - val_loss: 0.1510 - val__f_score: 0.9198 - lr: 5.0500e-05\n",
      "Train on 186 samples, val on 21 samples, with batch size 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\gpu_tensorflow2\\lib\\site-packages\\ipykernel_launcher.py:437: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 4.881001504579459e-05.\n",
      "Epoch 51/100\n",
      "186/186 [==============================] - 69s 362ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.2707 - _f_score: 0.8350 - val_loss: 0.2059 - val__f_score: 0.8923 - lr: 4.8810e-05\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 4.7122000538448796e-05.\n",
      "Epoch 52/100\n",
      "186/186 [==============================] - 67s 361ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1679 - _f_score: 0.8958 - val_loss: 0.1923 - val__f_score: 0.8968 - lr: 4.7122e-05\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 4.543792462736932e-05.\n",
      "Epoch 53/100\n",
      "186/186 [==============================] - 66s 355ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1573 - _f_score: 0.8982 - val_loss: 0.1677 - val__f_score: 0.9067 - lr: 4.5438e-05\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 4.375975086973579e-05.\n",
      "Epoch 54/100\n",
      "186/186 [==============================] - 67s 359ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1628 - _f_score: 0.8924 - val_loss: 0.1578 - val__f_score: 0.9129 - lr: 4.3760e-05\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 4.2089435941081e-05.\n",
      "Epoch 55/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1449 - _f_score: 0.9043Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 86.2; mPA: 94.1; Accuracy: 97.95\n",
      "Get miou done.\n",
      "186/186 [==============================] - 70s 374ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1449 - _f_score: 0.9043 - val_loss: 0.1522 - val__f_score: 0.9169 - lr: 4.2089e-05\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 4.042892735389462e-05.\n",
      "Epoch 56/100\n",
      "186/186 [==============================] - 67s 360ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1409 - _f_score: 0.9059 - val_loss: 0.1679 - val__f_score: 0.9089 - lr: 4.0429e-05\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 3.878016118691088e-05.\n",
      "Epoch 57/100\n",
      "186/186 [==============================] - 66s 354ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1440 - _f_score: 0.9067 - val_loss: 0.1561 - val__f_score: 0.9141 - lr: 3.8780e-05\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 3.7145059827727304e-05.\n",
      "Epoch 58/100\n",
      "186/186 [==============================] - 66s 354ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1330 - _f_score: 0.9147 - val_loss: 0.1540 - val__f_score: 0.9137 - lr: 3.7145e-05\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 3.552552973138674e-05.\n",
      "Epoch 59/100\n",
      "186/186 [==============================] - 65s 352ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1358 - _f_score: 0.9143 - val_loss: 0.1516 - val__f_score: 0.9163 - lr: 3.5526e-05\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 3.3923459197536184e-05.\n",
      "Epoch 60/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1321 - _f_score: 0.9097Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 85.82; mPA: 94.37; Accuracy: 97.86\n",
      "Get miou done.\n",
      "186/186 [==============================] - 69s 370ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1321 - _f_score: 0.9097 - val_loss: 0.1579 - val__f_score: 0.9145 - lr: 3.3923e-05\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 3.234071616875371e-05.\n",
      "Epoch 61/100\n",
      "186/186 [==============================] - 66s 357ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1401 - _f_score: 0.9049 - val_loss: 0.1410 - val__f_score: 0.9211 - lr: 3.2341e-05\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 3.077914605261105e-05.\n",
      "Epoch 62/100\n",
      "186/186 [==============================] - 66s 357ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1281 - _f_score: 0.9132 - val_loss: 0.1568 - val__f_score: 0.9131 - lr: 3.0779e-05\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 2.9240569570010955e-05.\n",
      "Epoch 63/100\n",
      "186/186 [==============================] - 66s 356ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1331 - _f_score: 0.9091 - val_loss: 0.1381 - val__f_score: 0.9230 - lr: 2.9241e-05\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 2.772678063230797e-05.\n",
      "Epoch 64/100\n",
      "186/186 [==============================] - 66s 355ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1307 - _f_score: 0.9125 - val_loss: 0.1388 - val__f_score: 0.9221 - lr: 2.7727e-05\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 2.6239544249688147e-05.\n",
      "Epoch 65/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1149 - _f_score: 0.9225Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 86.5; mPA: 93.93; Accuracy: 98.02\n",
      "Get miou done.\n",
      "186/186 [==============================] - 69s 370ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1149 - _f_score: 0.9225 - val_loss: 0.1491 - val__f_score: 0.9179 - lr: 2.6240e-05\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 2.478059447324605e-05.\n",
      "Epoch 66/100\n",
      "186/186 [==============================] - 66s 354ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1356 - _f_score: 0.9073 - val_loss: 0.1386 - val__f_score: 0.9238 - lr: 2.4781e-05\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 2.3351632373158714e-05.\n",
      "Epoch 67/100\n",
      "186/186 [==============================] - 67s 359ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1343 - _f_score: 0.9142 - val_loss: 0.1565 - val__f_score: 0.9141 - lr: 2.3352e-05\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 2.195432405531408e-05.\n",
      "Epoch 68/100\n",
      "186/186 [==============================] - 66s 355ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1228 - _f_score: 0.9158 - val_loss: 0.1525 - val__f_score: 0.9156 - lr: 2.1954e-05\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 2.0590298718705826e-05.\n",
      "Epoch 69/100\n",
      "186/186 [==============================] - 66s 354ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1124 - _f_score: 0.9225 - val_loss: 0.1329 - val__f_score: 0.9263 - lr: 2.0590e-05\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 1.9261146755860384e-05.\n",
      "Epoch 70/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1173 - _f_score: 0.9209Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.0; mPA: 93.43; Accuracy: 98.32\n",
      "Get miou done.\n",
      "186/186 [==============================] - 69s 372ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1173 - _f_score: 0.9209 - val_loss: 0.1333 - val__f_score: 0.9258 - lr: 1.9261e-05\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1.7968417898510374e-05.\n",
      "Epoch 71/100\n",
      "186/186 [==============================] - 66s 356ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1318 - _f_score: 0.9054 - val_loss: 0.1317 - val__f_score: 0.9273 - lr: 1.7968e-05\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1.6713619410676617e-05.\n",
      "Epoch 72/100\n",
      "186/186 [==============================] - 66s 355ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1203 - _f_score: 0.9218 - val_loss: 0.1360 - val__f_score: 0.9244 - lr: 1.6714e-05\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1.54982143312659e-05.\n",
      "Epoch 73/100\n",
      "186/186 [==============================] - 67s 359ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1210 - _f_score: 0.9177 - val_loss: 0.1413 - val__f_score: 0.9238 - lr: 1.5498e-05\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1.4323619768232857e-05.\n",
      "Epoch 74/100\n",
      "186/186 [==============================] - 66s 356ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1152 - _f_score: 0.9261 - val_loss: 0.1337 - val__f_score: 0.9257 - lr: 1.4324e-05\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1.3191205246295623e-05.\n",
      "Epoch 75/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1088 - _f_score: 0.9261Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.34; mPA: 93.97; Accuracy: 98.36\n",
      "Get miou done.\n",
      "186/186 [==============================] - 69s 372ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1088 - _f_score: 0.9261 - val_loss: 0.1319 - val__f_score: 0.9282 - lr: 1.3191e-05\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1.2102291110131227e-05.\n",
      "Epoch 76/100\n",
      "186/186 [==============================] - 66s 357ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1091 - _f_score: 0.9296 - val_loss: 0.1328 - val__f_score: 0.9267 - lr: 1.2102e-05\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1.1058146984912729e-05.\n",
      "Epoch 77/100\n",
      "186/186 [==============================] - 66s 354ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1144 - _f_score: 0.9235 - val_loss: 0.1351 - val__f_score: 0.9263 - lr: 1.1058e-05\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1.0059990295983123e-05.\n",
      "Epoch 78/100\n",
      "186/186 [==============================] - 66s 353ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1122 - _f_score: 0.9229 - val_loss: 0.1452 - val__f_score: 0.9218 - lr: 1.0060e-05\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 9.108984849391815e-06.\n",
      "Epoch 79/100\n",
      "186/186 [==============================] - 66s 356ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1176 - _f_score: 0.9171 - val_loss: 0.1309 - val__f_score: 0.9268 - lr: 9.1090e-06\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 8.206239474948827e-06.\n",
      "Epoch 80/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1125 - _f_score: 0.9230Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.61; mPA: 93.56; Accuracy: 98.42\n",
      "Get miou done.\n",
      "186/186 [==============================] - 69s 372ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1125 - _f_score: 0.9230 - val_loss: 0.1277 - val__f_score: 0.9301 - lr: 8.2062e-06\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 7.3528067333788184e-06.\n",
      "Epoch 81/100\n",
      "186/186 [==============================] - 66s 357ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1204 - _f_score: 0.9251 - val_loss: 0.1337 - val__f_score: 0.9262 - lr: 7.3528e-06\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 6.549681689082427e-06.\n",
      "Epoch 82/100\n",
      "186/186 [==============================] - 66s 357ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1118 - _f_score: 0.9237 - val_loss: 0.1270 - val__f_score: 0.9303 - lr: 6.5497e-06\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 5.79780074993563e-06.\n",
      "Epoch 83/100\n",
      "186/186 [==============================] - 66s 355ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1142 - _f_score: 0.9197 - val_loss: 0.1274 - val__f_score: 0.9293 - lr: 5.7978e-06\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 5.098040575480075e-06.\n",
      "Epoch 84/100\n",
      "186/186 [==============================] - 66s 354ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1075 - _f_score: 0.9341 - val_loss: 0.1364 - val__f_score: 0.9253 - lr: 5.0980e-06\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 4.451217054777265e-06.\n",
      "Epoch 85/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1218 - _f_score: 0.9260Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.48; mPA: 93.65; Accuracy: 98.4\n",
      "Get miou done.\n",
      "186/186 [==============================] - 69s 373ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1218 - _f_score: 0.9260 - val_loss: 0.1286 - val__f_score: 0.9288 - lr: 4.4512e-06\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 3.858084355118391e-06.\n",
      "Epoch 86/100\n",
      "186/186 [==============================] - 67s 359ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1053 - _f_score: 0.9317 - val_loss: 0.1316 - val__f_score: 0.9272 - lr: 3.8581e-06\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 3.319334042699034e-06.\n",
      "Epoch 87/100\n",
      "186/186 [==============================] - 67s 358ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1210 - _f_score: 0.9174 - val_loss: 0.1315 - val__f_score: 0.9275 - lr: 3.3193e-06\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 2.8355942762839377e-06.\n",
      "Epoch 88/100\n",
      "186/186 [==============================] - 67s 358ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1124 - _f_score: 0.9213 - val_loss: 0.1295 - val__f_score: 0.9288 - lr: 2.8356e-06\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 2.407429074801893e-06.\n",
      "Epoch 89/100\n",
      "186/186 [==============================] - 67s 360ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1213 - _f_score: 0.9305 - val_loss: 0.1307 - val__f_score: 0.9278 - lr: 2.4074e-06\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 2.0353376597250214e-06.\n",
      "Epoch 90/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1095 - _f_score: 0.9246Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.05; mPA: 92.8; Accuracy: 98.35\n",
      "Get miou done.\n",
      "186/186 [==============================] - 70s 375ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1095 - _f_score: 0.9246 - val_loss: 0.1354 - val__f_score: 0.9259 - lr: 2.0353e-06\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 1.7197538729987554e-06.\n",
      "Epoch 91/100\n",
      "186/186 [==============================] - 67s 360ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1044 - _f_score: 0.9298 - val_loss: 0.1299 - val__f_score: 0.9288 - lr: 1.7198e-06\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 1.4610456712016333e-06.\n",
      "Epoch 92/100\n",
      "186/186 [==============================] - 67s 360ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1100 - _f_score: 0.9226 - val_loss: 0.1282 - val__f_score: 0.9297 - lr: 1.4610e-06\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 1.2595146965243057e-06.\n",
      "Epoch 93/100\n",
      "186/186 [==============================] - 67s 359ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1121 - _f_score: 0.9290 - val_loss: 0.1291 - val__f_score: 0.9291 - lr: 1.2595e-06\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 1.1153959250683067e-06.\n",
      "Epoch 94/100\n",
      "186/186 [==============================] - 67s 361ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1074 - _f_score: 0.9351 - val_loss: 0.1276 - val__f_score: 0.9300 - lr: 1.1154e-06\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 1.028857392874386e-06.\n",
      "Epoch 95/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.0985 - _f_score: 0.9340Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.69; mPA: 93.71; Accuracy: 98.43\n",
      "Get miou done.\n",
      "186/186 [==============================] - 70s 377ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.0985 - _f_score: 0.9340 - val_loss: 0.1271 - val__f_score: 0.9302 - lr: 1.0289e-06\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 96/100\n",
      "186/186 [==============================] - 67s 361ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1150 - _f_score: 0.9245 - val_loss: 0.1265 - val__f_score: 0.9302 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 97/100\n",
      "186/186 [==============================] - 67s 360ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1149 - _f_score: 0.9280 - val_loss: 0.1266 - val__f_score: 0.9302 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 98/100\n",
      "186/186 [==============================] - 67s 361ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1051 - _f_score: 0.9294 - val_loss: 0.1270 - val__f_score: 0.9299 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 99/100\n",
      "186/186 [==============================] - 67s 360ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1065 - _f_score: 0.9297 - val_loss: 0.1272 - val__f_score: 0.9298 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 100/100\n",
      "186/186 [==============================] - ETA: 0s - batch: 92.5000 - size: 1.0000 - loss: 0.1089 - _f_score: 0.9296Get miou.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate miou.\n",
      "Num classes 2\n",
      "===> mIoU: 88.64; mPA: 93.78; Accuracy: 98.42\n",
      "Get miou done.\n",
      "186/186 [==============================] - 70s 376ms/step - batch: 92.5000 - size: 1.0000 - loss: 0.1089 - _f_score: 0.9296 - val_loss: 0.1270 - val__f_score: 0.9299 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# %load train.py\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard)\n",
    "from keras.layers import Conv2D, Dense, DepthwiseConv2D\n",
    "#from keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "\n",
    "from nets.unet import Unet\n",
    "from nets.unet_training import (CE, Focal_Loss, dice_loss_with_CE,\n",
    "                                dice_loss_with_Focal_Loss, get_lr_scheduler)\n",
    "from utils.callbacks import EvalCallback, LossHistory, ParallelModelCheckpoint\n",
    "from utils.dataloader import UnetDataset\n",
    "from utils.utils import show_config\n",
    "from utils.utils_metrics import Iou_score, f_score\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "'''\n",
    "训练自己的目标检测模型一定需要注意以下几点：\n",
    "1、训练前仔细检查自己的格式是否满足要求，该库要求数据集格式为VOC格式，需要准备好的内容有输入图片和标签\n",
    "   输入图片为.jpg图片，无需固定大小，传入训练前会自动进行resize。\n",
    "   灰度图会自动转成RGB图片进行训练，无需自己修改。\n",
    "   输入图片如果后缀非jpg，需要自己批量转成jpg后再开始训练。\n",
    "\n",
    "   标签为png图片，无需固定大小，传入训练前会自动进行resize。\n",
    "   由于许多同学的数据集是网络上下载的，标签格式并不符合，需要再度处理。一定要注意！标签的每个像素点的值就是这个像素点所属的种类。\n",
    "   网上常见的数据集总共对输入图片分两类，背景的像素点值为0，目标的像素点值为255。这样的数据集可以正常运行但是预测是没有效果的！\n",
    "   需要改成，背景的像素点值为0，目标的像素点值为1。\n",
    "\n",
    "2、损失值的大小用于判断是否收敛，比较重要的是有收敛的趋势，即验证集损失不断下降，如果验证集损失基本上不改变的话，模型基本上就收敛了。\n",
    "   损失值的具体大小并没有什么意义，大和小只在于损失的计算方式，并不是接近于0才好。如果想要让损失好看点，可以直接到对应的损失函数里面除上10000。\n",
    "   训练过程中的损失\n",
    "   值会保存在logs文件夹下的loss_%Y_%m_%d_%H_%M_%S文件夹中\n",
    "   \n",
    "3、训练好的权值文件保存在logs文件夹中，每个训练世代（Epoch）包含若干训练步长（Step），每个训练步长（Step）进行一次梯度下降。\n",
    "   如果只是训练了几个Step是不会保存的，Epoch和Step的概念要捋清楚一下。\n",
    "'''\n",
    "if __name__ == \"__main__\":    \n",
    "    #---------------------------------------------------------------------#\n",
    "    #   train_gpu   训练用到的GPU\n",
    "    #               默认为第一张卡、双卡为[0, 1]、三卡为[0, 1, 2]\n",
    "    #               在使用多GPU时，每个卡上的batch为总batch除以卡的数量。\n",
    "    #---------------------------------------------------------------------#\n",
    "    train_gpu   = [0,]\n",
    "    #---------------------------------------------------------------------#\n",
    "    #   num_classes     训练自己的数据集必须要修改的\n",
    "    #                   自己需要的分类个数+1，如2+1\n",
    "    #---------------------------------------------------------------------#\n",
    "    num_classes     = 2\n",
    "    #-------------------------------#\n",
    "    #   主干网络选择\n",
    "    #   vgg\n",
    "    #   resnet50\n",
    "    #-------------------------------#\n",
    "    backbone        = \"vgg\"\n",
    "    #----------------------------------------------------------------------------------------------------------------------------#\n",
    "    #   权值文件的下载请看README，可以通过网盘下载。模型的 预训练权重 对不同数据集是通用的，因为特征是通用的。\n",
    "    #   模型的 预训练权重 比较重要的部分是 主干特征提取网络的权值部分，用于进行特征提取。\n",
    "    #   预训练权重对于99%的情况都必须要用，不用的话主干部分的权值太过随机，特征提取效果不明显，网络训练的结果也不会好\n",
    "    #   训练自己的数据集时提示维度不匹配正常，预测的东西都不一样了自然维度不匹配\n",
    "    #\n",
    "    #   如果训练过程中存在中断训练的操作，可以将model_path设置成logs文件夹下的权值文件，将已经训练了一部分的权值再次载入。\n",
    "    #   同时修改下方的 冻结阶段 或者 解冻阶段 的参数，来保证模型epoch的连续性。\n",
    "    #   \n",
    "    #   当model_path = ''的时候不加载整个模型的权值。\n",
    "    #\n",
    "    #   此处使用的是整个模型的权重，因此是在train.py进行加载的。\n",
    "    #   如果想要让模型从主干的预训练权值开始训练，则设置model_path为主干网络的权值，此时仅加载主干。\n",
    "    #   如果想要让模型从0开始训练，则设置model_path = ''，下面的Freeze_Train = Fasle，此时从0开始训练，且没有冻结主干的过程。\n",
    "    #   \n",
    "    #   一般来讲，网络从0开始的训练效果会很差，因为权值太过随机，特征提取效果不明显，因此非常、非常、非常不建议大家从0开始训练！\n",
    "    #   如果一定要从0开始，可以了解imagenet数据集，首先训练分类模型，获得网络的主干部分权值，分类模型的 主干部分 和该模型通用，基于此进行训练。\n",
    "    #----------------------------------------------------------------------------------------------------------------------------#\n",
    "    model_path      = \"model_data/unet_vgg_voc.h5\"\n",
    "    #---------------------------------------------------------#\n",
    "    #   input_shape 输入图片的大小，32的倍数\n",
    "    #---------------------------------------------------------#\n",
    "    input_shape     = [512, 512]\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------------------------#\n",
    "    #   训练分为两个阶段，分别是冻结阶段和解冻阶段。设置冻结阶段是为了满足机器性能不足的同学的训练需求。\n",
    "    #   冻结训练需要的显存较小，显卡非常差的情况下，可设置Freeze_Epoch等于UnFreeze_Epoch，此时仅仅进行冻结训练。\n",
    "    #   \n",
    "    #   在此提供若干参数设置建议，各位训练者根据自己的需求进行灵活调整：\n",
    "    #   （一）从整个模型的预训练权重开始训练： \n",
    "    #       Adam：\n",
    "    #           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 100，Freeze_Train = True，optimizer_type = 'adam'，Init_lr = 1e-4，weight_decay = 0。（冻结）\n",
    "    #           Init_Epoch = 0，UnFreeze_Epoch = 100，Freeze_Train = False，optimizer_type = 'adam'，Init_lr = 1e-4，weight_decay = 0。（不冻结）\n",
    "    #       SGD：\n",
    "    #           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 100，Freeze_Train = True，optimizer_type = 'sgd'，Init_lr = 1e-2，weight_decay = 1e-4。（冻结）\n",
    "    #           Init_Epoch = 0，UnFreeze_Epoch = 100，Freeze_Train = False，optimizer_type = 'sgd'，Init_lr = 1e-2，weight_decay = 1e-4。（不冻结）\n",
    "    #       其中：UnFreeze_Epoch可以在100-300之间调整。\n",
    "    #   （二）从主干网络的预训练权重开始训练：\n",
    "    #       Adam：\n",
    "    #           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 100，Freeze_Train = True，optimizer_type = 'adam'，Init_lr = 1e-4，weight_decay = 0。（冻结）\n",
    "    #           Init_Epoch = 0，UnFreeze_Epoch = 100，Freeze_Train = False，optimizer_type = 'adam'，Init_lr = 1e-4，weight_decay = 0。（不冻结）\n",
    "    #       SGD：\n",
    "    #           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 120，Freeze_Train = True，optimizer_type = 'sgd'，Init_lr = 1e-2，weight_decay = 1e-4。（冻结）\n",
    "    #           Init_Epoch = 0，UnFreeze_Epoch = 120，Freeze_Train = False，optimizer_type = 'sgd'，Init_lr = 1e-2，weight_decay = 1e-4。（不冻结）\n",
    "    #       其中：由于从主干网络的预训练权重开始训练，主干的权值不一定适合语义分割，需要更多的训练跳出局部最优解。\n",
    "    #             UnFreeze_Epoch可以在120-300之间调整。\n",
    "    #             Adam相较于SGD收敛的快一些。因此UnFreeze_Epoch理论上可以小一点，但依然推荐更多的Epoch。\n",
    "    #   （三）batch_size的设置：\n",
    "    #       在显卡能够接受的范围内，以大为好。显存不足与数据集大小无关，提示显存不足（OOM或者CUDA out of memory）请调小batch_size。\n",
    "    #       由于resnet50中有BatchNormalization层\n",
    "    #       当主干为resnet50的时候batch_size不可为1\n",
    "    #       正常情况下Freeze_batch_size建议为Unfreeze_batch_size的1-2倍。不建议设置的差距过大，因为关系到学习率的自动调整。\n",
    "    #----------------------------------------------------------------------------------------------------------------------------#\n",
    "    #------------------------------------------------------------------#\n",
    "    #   冻结阶段训练参数\n",
    "    #   此时模型的主干被冻结了，特征提取网络不发生改变\n",
    "    #   占用的显存较小，仅对网络进行微调\n",
    "    #   Init_Epoch          模型当前开始的训练世代，其值可以大于Freeze_Epoch，如设置：\n",
    "    #                       Init_Epoch = 60、Freeze_Epoch = 50、UnFreeze_Epoch = 100\n",
    "    #                       会跳过冻结阶段，直接从60代开始，并调整对应的学习率。\n",
    "    #                       （断点续练时使用）\n",
    "    #   Freeze_Epoch        模型冻结训练的Freeze_Epoch\n",
    "    #                       (当Freeze_Train=False时失效)\n",
    "    #   Freeze_batch_size   模型冻结训练的batch_size\n",
    "    #                       (当Freeze_Train=False时失效)\n",
    "    #------------------------------------------------------------------#\n",
    "    Init_Epoch          = 0\n",
    "    Freeze_Epoch        = 50\n",
    "    Freeze_batch_size   = 1\n",
    "    #------------------------------------------------------------------#\n",
    "    #   解冻阶段训练参数\n",
    "    #   此时模型的主干不被冻结了，特征提取网络会发生改变\n",
    "    #   占用的显存较大，网络所有的参数都会发生改变\n",
    "    #   UnFreeze_Epoch          模型总共训练的epoch\n",
    "    #   Unfreeze_batch_size     模型在解冻后的batch_size\n",
    "    #------------------------------------------------------------------#\n",
    "    UnFreeze_Epoch      = 100\n",
    "    Unfreeze_batch_size = 1\n",
    "    #------------------------------------------------------------------#\n",
    "    #   Freeze_Train    是否进行冻结训练\n",
    "    #                   默认先冻结主干训练后解冻训练。\n",
    "    #------------------------------------------------------------------#\n",
    "    Freeze_Train        = True\n",
    "\n",
    "    #------------------------------------------------------------------#\n",
    "    #   其它训练参数：学习率、优化器、学习率下降有关\n",
    "    #------------------------------------------------------------------#\n",
    "    #------------------------------------------------------------------#\n",
    "    #   Init_lr         模型的最大学习率\n",
    "    #                   当使用Adam优化器时建议设置  Init_lr=1e-4\n",
    "    #                   当使用SGD优化器时建议设置   Init_lr=1e-2\n",
    "    #   Min_lr          模型的最小学习率，默认为最大学习率的0.01\n",
    "    #------------------------------------------------------------------#\n",
    "    Init_lr             = 1e-4\n",
    "    Min_lr              = Init_lr * 0.01\n",
    "    #------------------------------------------------------------------#\n",
    "    #   optimizer_type  使用到的优化器种类，可选的有adam、sgd\n",
    "    #                   当使用Adam优化器时建议设置  Init_lr=1e-4\n",
    "    #                   当使用SGD优化器时建议设置   Init_lr=1e-2\n",
    "    #   momentum        优化器内部使用到的momentum参数\n",
    "    #   weight_decay    权值衰减，可防止过拟合\n",
    "    #                   adam会导致weight_decay错误，使用adam时建议设置为0。\n",
    "    #------------------------------------------------------------------#\n",
    "    optimizer_type      = \"adam\"\n",
    "    momentum            = 0.9\n",
    "    weight_decay        = 0\n",
    "    #------------------------------------------------------------------#\n",
    "    #   lr_decay_type   使用到的学习率下降方式，可选的有'step'、'cos'\n",
    "    #------------------------------------------------------------------#\n",
    "    lr_decay_type       = 'cos'\n",
    "    #------------------------------------------------------------------#\n",
    "    #   save_period     多少个epoch保存一次权值\n",
    "    #------------------------------------------------------------------#\n",
    "    save_period         = 5\n",
    "    #------------------------------------------------------------------#\n",
    "    #   save_dir        权值与日志文件保存的文件夹\n",
    "    #------------------------------------------------------------------#\n",
    "    save_dir            = 'logs'\n",
    "    #------------------------------------------------------------------#\n",
    "    #   eval_flag       是否在训练时进行评估，评估对象为验证集\n",
    "    #   eval_period     代表多少个epoch评估一次，不建议频繁的评估\n",
    "    #                   评估需要消耗较多的时间，频繁评估会导致训练非常慢\n",
    "    #   此处获得的mAP会与get_map.py获得的会有所不同，原因有二：\n",
    "    #   （一）此处获得的mAP为验证集的mAP。\n",
    "    #   （二）此处设置评估参数较为保守，目的是加快评估速度。\n",
    "    #------------------------------------------------------------------#\n",
    "    eval_flag           = True\n",
    "    eval_period         = 5\n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    #   VOCdevkit_path  数据集路径\n",
    "    #------------------------------------------------------------------#\n",
    "    VOCdevkit_path  = 'VOCdevkit'\n",
    "    #------------------------------------------------------------------#\n",
    "    #   建议选项：\n",
    "    #   种类少（几类）时，设置为True\n",
    "    #   种类多（十几类）时，如果batch_size比较大（10以上），那么设置为True\n",
    "    #   种类多（十几类）时，如果batch_size比较小（10以下），那么设置为False\n",
    "    #------------------------------------------------------------------#\n",
    "    dice_loss       = True\n",
    "    #------------------------------------------------------------------#\n",
    "    #   是否使用focal loss来防止正负样本不平衡\n",
    "    #------------------------------------------------------------------#\n",
    "    focal_loss      = False\n",
    "    #------------------------------------------------------------------#\n",
    "    #   是否给不同种类赋予不同的损失权值，默认是平衡的。\n",
    "    #   设置的话，注意设置成numpy形式的，长度和num_classes一样。\n",
    "    #   如：\n",
    "    #   num_classes = 3\n",
    "    #   cls_weights = np.array([1, 2, 3], np.float32)\n",
    "    #------------------------------------------------------------------#\n",
    "    cls_weights     = np.ones([num_classes], np.float32)\n",
    "    #-------------------------------------------------------------------#\n",
    "    #   用于设置是否使用多线程读取数据，1代表关闭多线程\n",
    "    #   开启后会加快数据读取速度，但是会占用更多内存\n",
    "    #   在IO为瓶颈的时候再开启多线程，即GPU运算速度远大于读取图片的速度。\n",
    "    #-------------------------------------------------------------------#\n",
    "    num_workers     = 1\n",
    "\n",
    "    #------------------------------------------------------#\n",
    "    #   设置用到的显卡\n",
    "    #------------------------------------------------------#\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]  = ','.join(str(x) for x in train_gpu)\n",
    "    ngpus_per_node                      = len(train_gpu)\n",
    "    print('Number of devices: {}'.format(ngpus_per_node))\n",
    "    \n",
    "    #------------------------------------------------------#\n",
    "    #   获取model\n",
    "    #------------------------------------------------------#\n",
    "    model_body = Unet([input_shape[0], input_shape[1], 3], num_classes, backbone)\n",
    "    if model_path != '':\n",
    "        #------------------------------------------------------#\n",
    "        #   载入预训练权重\n",
    "        #------------------------------------------------------#\n",
    "        model_body.load_weights(model_path, by_name=True, skip_mismatch=True)\n",
    "\n",
    "    if ngpus_per_node > 1:\n",
    "        model = multi_gpu_model(model_body, gpus=ngpus_per_node)\n",
    "    else:\n",
    "        model = model_body\n",
    "\n",
    "    #--------------------------#\n",
    "    #   使用到的损失函数\n",
    "    #   如果focal_loss为true将采用Focal_Loss防止正负样本不均衡，否则采样普通的交叉熵损失\n",
    "    #   dice_loss为true时，将计算dicelosss，并添加到loss上。\n",
    "    #--------------------------#\n",
    "    if focal_loss:\n",
    "        if dice_loss:\n",
    "            loss = dice_loss_with_Focal_Loss(cls_weights)\n",
    "        else:\n",
    "            loss = Focal_Loss(cls_weights)\n",
    "    else:\n",
    "        if dice_loss:\n",
    "            loss = dice_loss_with_CE(cls_weights)\n",
    "        else:\n",
    "            loss = CE(cls_weights)\n",
    "\n",
    "    #---------------------------#\n",
    "    #   读取数据集对应的txt\n",
    "    #---------------------------#\n",
    "    with open(os.path.join(VOCdevkit_path, \"VOC2007/ImageSets/Segmentation/train.txt\"),\"r\") as f:\n",
    "        train_lines = f.readlines()\n",
    "    with open(os.path.join(VOCdevkit_path, \"VOC2007/ImageSets/Segmentation/val.txt\"),\"r\") as f:\n",
    "        val_lines = f.readlines()\n",
    "    num_train   = len(train_lines)\n",
    "    num_val     = len(val_lines)\n",
    "\n",
    "    show_config(\n",
    "        num_classes = num_classes, backbone = backbone, model_path = model_path, input_shape = input_shape, \\\n",
    "        Init_Epoch = Init_Epoch, Freeze_Epoch = Freeze_Epoch, UnFreeze_Epoch = UnFreeze_Epoch, Freeze_batch_size = Freeze_batch_size, Unfreeze_batch_size = Unfreeze_batch_size, Freeze_Train = Freeze_Train, \\\n",
    "        Init_lr = Init_lr, Min_lr = Min_lr, optimizer_type = optimizer_type, momentum = momentum, lr_decay_type = lr_decay_type, \\\n",
    "        save_period = save_period, save_dir = save_dir, num_workers = num_workers, num_train = num_train, num_val = num_val\n",
    "    )\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, DepthwiseConv2D):\n",
    "                layer.add_loss(l2(weight_decay)(layer.depthwise_kernel))\n",
    "        elif isinstance(layer, Conv2D) or isinstance(layer, Dense):\n",
    "                layer.add_loss(l2(weight_decay)(layer.kernel))\n",
    "                \n",
    "    #------------------------------------------------------#\n",
    "    #   主干特征提取网络特征通用，冻结训练可以加快训练速度\n",
    "    #   也可以在训练初期防止权值被破坏。\n",
    "    #   Init_Epoch为起始世代\n",
    "    #   Freeze_Epoch为冻结训练的世代\n",
    "    #   Epoch总训练世代\n",
    "    #   提示OOM或者显存不足请调小Batch_size\n",
    "    #------------------------------------------------------#\n",
    "    if True:\n",
    "        if Freeze_Train:\n",
    "            #------------------------------------#\n",
    "            #   冻结一定部分训练\n",
    "            #------------------------------------#\n",
    "            if backbone == \"vgg\":\n",
    "                freeze_layers = 17\n",
    "            elif backbone == \"resnet50\":\n",
    "                freeze_layers = 172\n",
    "            else:\n",
    "                raise ValueError('Unsupported backbone - `{}`, Use vgg, resnet50.'.format(backbone))\n",
    "            for i in range(freeze_layers): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(freeze_layers, len(model_body.layers)))\n",
    "\n",
    "        #-------------------------------------------------------------------#\n",
    "        #   如果不冻结训练的话，直接设置batch_size为Unfreeze_batch_size\n",
    "        #-------------------------------------------------------------------#\n",
    "        batch_size  = Freeze_batch_size if Freeze_Train else Unfreeze_batch_size\n",
    "        start_epoch = Init_Epoch\n",
    "        end_epoch   = Freeze_Epoch if Freeze_Train else UnFreeze_Epoch\n",
    "        \n",
    "        #-------------------------------------------------------------------#\n",
    "        #   判断当前batch_size，自适应调整学习率\n",
    "        #-------------------------------------------------------------------#\n",
    "        nbs             = 16\n",
    "        lr_limit_max    = 1e-4 if optimizer_type == 'adam' else 1e-1\n",
    "        lr_limit_min    = 1e-4 if optimizer_type == 'adam' else 5e-4\n",
    "        Init_lr_fit     = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "        Min_lr_fit      = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "\n",
    "        optimizer = {\n",
    "            'adam'  : tf.keras.optimizers.Adam(lr = Init_lr_fit, beta_1 = momentum),\n",
    "            'sgd'   : SGD(lr = Init_lr_fit, momentum = momentum, nesterov=True)\n",
    "        }[optimizer_type]\n",
    "        model.compile(loss = loss,\n",
    "                optimizer = optimizer,\n",
    "                metrics = [f_score()])\n",
    "    \n",
    "        #---------------------------------------#\n",
    "        #   获得学习率下降的公式\n",
    "        #---------------------------------------#\n",
    "        lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n",
    "\n",
    "        epoch_step          = num_train // batch_size\n",
    "        epoch_step_val      = num_val // batch_size\n",
    "\n",
    "        if epoch_step == 0 or epoch_step_val == 0:\n",
    "            raise ValueError('数据集过小，无法进行训练，请扩充数据集。')\n",
    "\n",
    "        train_dataloader    = UnetDataset(train_lines, input_shape, batch_size, num_classes, True, VOCdevkit_path)\n",
    "        val_dataloader      = UnetDataset(val_lines, input_shape, batch_size, num_classes, False, VOCdevkit_path)\n",
    "\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        #   训练参数的设置\n",
    "        #   logging         用于设置tensorboard的保存地址\n",
    "        #   checkpoint      用于设置权值保存的细节，period用于修改多少epoch保存一次\n",
    "        #   lr_scheduler       用于设置学习率下降的方式\n",
    "        #   early_stopping  用于设定早停，val_loss多次不下降自动结束训练，表示模型基本收敛\n",
    "        #-------------------------------------------------------------------------------#\n",
    "        time_str        = datetime.datetime.strftime(datetime.datetime.now(),'%Y_%m_%d_%H_%M_%S')\n",
    "        log_dir         = os.path.join(save_dir, \"loss_\" + str(time_str))\n",
    "        logging         = TensorBoard(log_dir)\n",
    "        loss_history    = LossHistory(log_dir)\n",
    "        if ngpus_per_node > 1:\n",
    "            checkpoint      = ParallelModelCheckpoint(model_body, os.path.join(save_dir, \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = save_period)\n",
    "            checkpoint_last = ParallelModelCheckpoint(model_body, os.path.join(save_dir, \"last_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = 1)\n",
    "            checkpoint_best = ParallelModelCheckpoint(model_body, os.path.join(save_dir, \"best_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = True, period = 1)\n",
    "        else:\n",
    "            checkpoint      = ModelCheckpoint(os.path.join(save_dir, \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = save_period)\n",
    "            checkpoint_last = ModelCheckpoint(os.path.join(save_dir, \"last_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = 1)\n",
    "            checkpoint_best = ModelCheckpoint(os.path.join(save_dir, \"best_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = True, period = 1)\n",
    "        early_stopping  = EarlyStopping(monitor='val_loss', min_delta = 0, patience = 10, verbose = 1)\n",
    "        lr_scheduler    = LearningRateScheduler(lr_scheduler_func, verbose = 1)\n",
    "        eval_callback   = EvalCallback(model_body, input_shape, num_classes, val_lines, VOCdevkit_path, log_dir, \\\n",
    "                                        eval_flag=eval_flag, period=eval_period)\n",
    "        callbacks       = [logging, loss_history, checkpoint, checkpoint_last, checkpoint_best, lr_scheduler, eval_callback]\n",
    "\n",
    "        if start_epoch < end_epoch:\n",
    "            print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "            model.fit_generator(\n",
    "                generator           = train_dataloader,\n",
    "                steps_per_epoch     = epoch_step,\n",
    "                validation_data     = val_dataloader,\n",
    "                validation_steps    = epoch_step_val,\n",
    "                epochs              = end_epoch,\n",
    "                initial_epoch       = start_epoch,\n",
    "                use_multiprocessing = True if num_workers > 1 else False,\n",
    "                workers             = num_workers,\n",
    "                callbacks           = callbacks\n",
    "            )\n",
    "        #---------------------------------------#\n",
    "        #   如果模型有冻结学习部分\n",
    "        #   则解冻，并设置参数\n",
    "        #---------------------------------------#\n",
    "        if Freeze_Train:\n",
    "            batch_size  = Unfreeze_batch_size\n",
    "            start_epoch = Freeze_Epoch if start_epoch < Freeze_Epoch else start_epoch\n",
    "            end_epoch   = UnFreeze_Epoch\n",
    "                \n",
    "            #-------------------------------------------------------------------#\n",
    "            #   判断当前batch_size，自适应调整学习率\n",
    "            #-------------------------------------------------------------------#\n",
    "            nbs             = 16\n",
    "            lr_limit_max    = 1e-4 if optimizer_type == 'adam' else 1e-1\n",
    "            lr_limit_min    = 1e-4 if optimizer_type == 'adam' else 5e-4\n",
    "            Init_lr_fit     = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "            Min_lr_fit      = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "            #---------------------------------------#\n",
    "            #   获得学习率下降的公式\n",
    "            #---------------------------------------#\n",
    "            lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n",
    "            lr_scheduler    = LearningRateScheduler(lr_scheduler_func, verbose = 1)\n",
    "            callbacks       = [logging, loss_history, checkpoint, checkpoint_last, checkpoint_best, lr_scheduler, eval_callback]\n",
    "            \n",
    "            for i in range(len(model_body.layers)): \n",
    "                model_body.layers[i].trainable = True\n",
    "            model.compile(loss = loss,\n",
    "                    optimizer = optimizer,\n",
    "                    metrics = [f_score()])\n",
    "\n",
    "            epoch_step      = num_train // batch_size\n",
    "            epoch_step_val  = num_val // batch_size\n",
    "\n",
    "            if epoch_step == 0 or epoch_step_val == 0:\n",
    "                raise ValueError(\"数据集过小，无法继续进行训练，请扩充数据集。\")\n",
    "\n",
    "            train_dataloader.batch_size    = Unfreeze_batch_size\n",
    "            val_dataloader.batch_size      = Unfreeze_batch_size\n",
    "\n",
    "            print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "            model.fit_generator(\n",
    "                generator           = train_dataloader,\n",
    "                steps_per_epoch     = epoch_step,\n",
    "                validation_data     = val_dataloader,\n",
    "                validation_steps    = epoch_step_val,\n",
    "                epochs              = end_epoch,\n",
    "                initial_epoch       = start_epoch,\n",
    "                use_multiprocessing = True if num_workers > 1 else False,\n",
    "                workers             = num_workers,\n",
    "                callbacks           = callbacks\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48590dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tensorflow2",
   "language": "python",
   "name": "gpu_tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
